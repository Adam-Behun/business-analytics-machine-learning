{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach uses deep learning techniques implemented using tensorflow and keras\n",
    "Official Kaggle score = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 14:40:30.698226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-14 14:40:30.761591: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-14 14:40:31.044023: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-14 14:40:31.046122: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 14:40:32.518506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,), (28000, 784))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['label'].astype('float32')\n",
    "X_train = train.drop(['label'], axis=1).astype('int32')\n",
    "X_test = test.astype('float32')\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 28, 28, 1), (28000, 28, 28, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    4\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train['label'].head())\n",
    "y_train[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1][:,:,0])\n",
    "plt.title(y_train[1].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Predict\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " layer_conv1 (Conv2D)        (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " maxPool1 (MaxPooling2D)     (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " layer_conv2 (Conv2D)        (None, 14, 14, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " maxPool2 (MaxPooling2D)     (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " maxPool3 (MaxPooling2D)     (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " fc0 (Dense)                 (None, 64)                18496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,770\n",
      "Trainable params: 49,514\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a CNN model\n",
    "input_shape = (28,28,1)\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "# layer 1\n",
    "x = Conv2D(64,(3,3),strides=(1,1),name='layer_conv1',padding='same')(X_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2,2),name='maxPool1')(x)\n",
    "# layer 2\n",
    "x = Conv2D(32,(3,3),strides=(1,1),name='layer_conv2',padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2,2),name='maxPool2')(x)\n",
    "# layer 3\n",
    "x = Conv2D(32,(3,3),strides=(1,1),name='conv3',padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2,2), name='maxPool3')(x)\n",
    "# fc\n",
    "x = Flatten()(x)\n",
    "x = Dense(64,activation ='relu',name='fc0')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(32,activation ='relu',name='fc1')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(10,activation ='softmax',name='fc2')(x)\n",
    "\n",
    "conv_model = Model(inputs=X_input, outputs=x, name='Predict')\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "378/378 [==============================] - 13s 32ms/step - loss: 0.5532 - accuracy: 0.8204 - val_loss: 0.4863 - val_accuracy: 0.9157\n",
      "Epoch 2/10\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.1430 - accuracy: 0.9596 - val_loss: 0.0752 - val_accuracy: 0.9798\n",
      "Epoch 3/10\n",
      "378/378 [==============================] - 12s 33ms/step - loss: 0.1009 - accuracy: 0.9723 - val_loss: 0.0541 - val_accuracy: 0.9833\n",
      "Epoch 4/10\n",
      "378/378 [==============================] - 13s 34ms/step - loss: 0.0806 - accuracy: 0.9786 - val_loss: 0.0575 - val_accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "378/378 [==============================] - 13s 34ms/step - loss: 0.0689 - accuracy: 0.9812 - val_loss: 0.0556 - val_accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "378/378 [==============================] - 14s 37ms/step - loss: 0.0590 - accuracy: 0.9844 - val_loss: 0.0470 - val_accuracy: 0.9893\n",
      "Epoch 7/10\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0510 - accuracy: 0.9859 - val_loss: 0.1101 - val_accuracy: 0.9724\n",
      "Epoch 8/10\n",
      "378/378 [==============================] - 12s 33ms/step - loss: 0.0445 - accuracy: 0.9880 - val_loss: 0.0714 - val_accuracy: 0.9829\n",
      "Epoch 9/10\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 0.0406 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0423 - accuracy: 0.9886 - val_loss: 0.0507 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc0e912560>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adam optimizer\n",
    "conv_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "conv_model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_cv,y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adambehun/.local/lib/python3.10/site-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.0383 - val_accuracy: 0.9907\n",
      "Epoch 2/30\n",
      "1182/1182 [==============================] - 18s 16ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.0376 - val_accuracy: 0.9902\n",
      "Epoch 3/30\n",
      "1182/1182 [==============================] - 17s 14ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0375 - val_accuracy: 0.9907\n",
      "Epoch 4/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 0.0373 - val_accuracy: 0.9902\n",
      "Epoch 5/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0372 - val_accuracy: 0.9905\n",
      "Epoch 6/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.0375 - val_accuracy: 0.9907\n",
      "Epoch 7/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.0372 - val_accuracy: 0.9905\n",
      "Epoch 8/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0369 - val_accuracy: 0.9907\n",
      "Epoch 9/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0371 - val_accuracy: 0.9910\n",
      "Epoch 10/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
      "Epoch 11/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0376 - val_accuracy: 0.9905\n",
      "Epoch 12/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0369 - val_accuracy: 0.9907\n",
      "Epoch 13/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.0365 - val_accuracy: 0.9907\n",
      "Epoch 14/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.0364 - val_accuracy: 0.9910\n",
      "Epoch 15/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0364 - val_accuracy: 0.9905\n",
      "Epoch 16/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
      "Epoch 17/30\n",
      "1182/1182 [==============================] - 17s 14ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 18/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 19/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.0369 - val_accuracy: 0.9905\n",
      "Epoch 20/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0366 - val_accuracy: 0.9907\n",
      "Epoch 21/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 22/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 23/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
      "Epoch 24/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0357 - val_accuracy: 0.9907\n",
      "Epoch 25/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0358 - val_accuracy: 0.9907\n",
      "Epoch 26/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0360 - val_accuracy: 0.9907\n",
      "Epoch 27/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 28/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.0367 - val_accuracy: 0.9905\n",
      "Epoch 29/30\n",
      "1182/1182 [==============================] - 18s 15ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0358 - val_accuracy: 0.9905\n",
      "Epoch 30/30\n",
      "1182/1182 [==============================] - 17s 15ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.0361 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc0ccb7d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD optimizer\n",
    "sgd = SGD(lr=0.0005, momentum=0.5, decay=0.0, nesterov=False) \n",
    "conv_model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "conv_model.fit(X_train, y_train, epochs=30, validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 5s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = conv_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "my_submission = pd.DataFrame({'ImageId': list(range(1, len(y_pred)+1)), 'Label': y_pred})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
