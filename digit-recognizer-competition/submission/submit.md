# The problem to be solved
The third challenge during the class business analytics in machine learning was focused around the MNIST ("Modified National Institute of Standards and Technology") dataset. This datasets consists of hand-written images and is well-known as the introduction to computer vision, however, this problem can be also seen as a classification problem and those are the two paths that I have decided to look into: computer vision including simple neural network (my best score) and classification methods before which I used some dimensionality reduction techniques such as Principal Component Analysis and t-SNE. The goal of my algorithm is to correctly identify digits from a dataset of thousands of hand-written images. I have tried different algorithms and dimensionality reduction techniques and my best score was achieved using a neural network, however, our class is more focused on supervised machine learning and so I will only briefly mention my implementation of this strategy. 

# Neural network 1 paragraph

To implement the neural network I first imported some python libraries into my jupyter notebook. I have used deep learning frameworkd tensorflow and keras. Then I have read the two datasets into their respective pandas dataframes. Then, using the seaborn library, I have visualized the distribution of the target variable "label" in the training dataset. Each bar in the graph represents the number of occurences of each unique value in the dataset. Then, normalizing the data = the value of each pixel in an image is represened by an int between 0 and 255. Normalization puts all the values between zero and one. This is useful because it can help our machine learning model to be faster and more accurate. Then, I have used one-hot encoding to convert categorical data into binary format again making it more suitable to train the the neural network. Then, I have split the training dataset into training and cross-validation to evaluate the performance of the dataset. Then, I have imported various modules from Keras - a deep learning library. I have used all these steps to build a convolutional neural network (well-suited for image recognition) with 3 convolutional layers, followed by two full-connected layers and finally an output layer. This approach has achieved my best score in the image recognition problem. 

# Principal component analysis
First of all I have found out that we have 784 independent variables and 1 dependent variable (label) of the digit in our train dataset. This, in my opinion, qualifies as a high-dimensional space which I want to transform into a lower dimensional space using dimensionality reduction techniques such as Principal Componenebt Analysis, Linear Disciminant Analysis, or t-SNE. I have started with PCA implemented using Python and some specific libraries with this functionality. I standardised the data as PCA is sensitive to scale. I have tried different number of components (150, 100, 50, 30) and decided to stick with 150 as that is already a pretty high number of independent variables and my PCA tells me that the first 150 components explain 0.81 of the variance in the train dataset. After that I fit different algorithms to this transformed dataset which now consists of 150 principle components explaining 0.81 of the variance in the dataset, instead of the original 784 variables. 

# Algorithms ran
After I finished my PCA, I have used the principal components to train a random forest and XGboost algorithms. 